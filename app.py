# -*- coding: utf-8 -*-
"""
ë‰´ìŠ¤ í¬ë¡¤ë§ + í‚¤ì›Œë“œ í•„í„° + ì¢…í•© ì½˜í…ì¸ (ë¸”ë¡œê·¸/ìŠ¤ë ˆë“œ/ì¹´ë“œë‰´ìŠ¤) Streamlit ì•±
"""
import streamlit as st

from crawler import crawl_articles, NewsArticle
from content_synthesis import synthesize, SynthesizedContent


def collect_all_keywords(articles: list[NewsArticle]) -> list[str]:
    seen = set()
    out = []
    for a in articles:
        for k in a.keywords:
            k = k.strip()
            if k and k not in seen:
                seen.add(k)
                out.append(k)
    return sorted(out)


def filter_articles_by_keyword(articles: list[NewsArticle], selected: list[str]) -> list[NewsArticle]:
    if not selected:
        return articles
    selected_set = set(selected)
    return [a for a in articles if selected_set & set(a.keywords)]


def main():
    st.set_page_config(page_title="ë‰´ìŠ¤ í¬ë¡¤ë§ & ì½˜í…ì¸  ìš”ì•½", layout="wide")
    st.title("ğŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ ê²€ìƒ‰ & ì½˜í…ì¸  ìš”ì•½")

    query = st.text_input("ê²€ìƒ‰ í‚¤ì›Œë“œ", placeholder="ì˜ˆ: ì¸ê³µì§€ëŠ¥ ê·œì œ")
    max_articles = st.slider("ìˆ˜ì§‘ ê¸°ì‚¬ ìˆ˜", min_value=5, max_value=10, value=10)

    if not query.strip():
        st.info("ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•œ ë’¤ ì‹¤í–‰í•˜ì„¸ìš”.")
        return

    if st.button("ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì‹¤í–‰"):
        with st.spinner("ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ìš”ì•½Â·í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘..."):
            articles = crawl_articles(query.strip(), max_articles=max_articles)
            st.session_state["articles"] = articles
            st.session_state["synthesized"] = None

    articles: list[NewsArticle] = st.session_state.get("articles") or []

    if not articles:
        st.stop()

    all_keywords = collect_all_keywords(articles)
    selected_keywords = st.multiselect(
        "í•µì‹¬í‚¤ì›Œë“œë¡œ í•„í„° (ì„ íƒí•œ í‚¤ì›Œë“œê°€ í¬í•¨ëœ ê¸°ì‚¬ë§Œ í‘œì‹œ)",
        options=all_keywords,
        default=[],
        key="keyword_filter",
    )
    filtered = filter_articles_by_keyword(articles, selected_keywords)

    st.subheader(f"ğŸ“° ë‰´ìŠ¤ ê¸°ì‚¬ ({len(filtered)}ê±´)")
    for i, a in enumerate(filtered, 1):
        with st.expander(f"{i}. {a.title[:80]}{'...' if len(a.title) > 80 else ''}"):
            st.markdown(f"**ìš”ì•½**\n{a.summary}")
            st.caption(f"í•µì‹¬í‚¤ì›Œë“œ: {', '.join(a.keywords) or '-'}")
            st.link_button("ê¸°ì‚¬ ë³´ê¸°", a.url)

    st.divider()
    st.subheader("ğŸ“‹ ì¢…í•© ì½˜í…ì¸ ")

    if st.session_state.get("synthesized") is None:
        if st.button("ì¢…í•© ì½˜í…ì¸  ìƒì„± (í•µì‹¬ ì£¼ì œ + ë¸”ë¡œê·¸/ìŠ¤ë ˆë“œ/ì¹´ë“œë‰´ìŠ¤)"):
            with st.spinner("ì¢…í•© ë¶„ì„ ì¤‘..."):
                syn = synthesize(articles)
                st.session_state["synthesized"] = syn

    syn: SynthesizedContent | None = st.session_state.get("synthesized")
    if syn:
        st.markdown("#### ğŸ¯ í•µì‹¬ ì£¼ì œ")
        st.info(syn.core_theme)

        st.markdown("#### ğŸ“ ë¸”ë¡œê·¸ ê¸€ (1200ì ë‚´ì™¸)")
        st.text_area("", value=syn.blog_post, height=280, disabled=True, key="blog")
        st.caption(f"ê¸€ì ìˆ˜: {len(syn.blog_post)}ì")

        st.markdown("#### ğŸ§µ ìŠ¤ë ˆë“œ/íŠ¸ìœ— (200ì ë‚´ì™¸)")
        st.text_area("", value=syn.thread_content, height=100, disabled=True, key="thread")
        st.caption(f"ê¸€ì ìˆ˜: {len(syn.thread_content)}ì")

        st.markdown("#### ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨ ì¹´ë“œë‰´ìŠ¤ (5ì¥)")
        for idx, card_text in enumerate(syn.instagram_cards, 1):
            st.markdown(f"**ì¹´ë“œ {idx}**")
            st.write(card_text)
            st.write("---")


if __name__ == "__main__":
    main()
